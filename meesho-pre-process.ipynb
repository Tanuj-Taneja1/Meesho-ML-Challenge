{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":84705,"databundleVersionId":9755748,"sourceType":"competition"},{"sourceId":9867123,"sourceType":"datasetVersion","datasetId":6051574},{"sourceId":206252942,"sourceType":"kernelVersion"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session*","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-11T08:46:33.452605Z","iopub.execute_input":"2024-11-11T08:46:33.453447Z","iopub.status.idle":"2024-11-11T08:46:34.344004Z","shell.execute_reply.started":"2024-11-11T08:46:33.453404Z","shell.execute_reply":"2024-11-11T08:46:34.342965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/meesho-ocr/df1_with_ocr.csv\")\ntest=pd.read_csv(\"/kaggle/input/meesho-ocr/df2_with_ocr.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-11-11T09:44:06.462263Z","iopub.execute_input":"2024-11-11T09:44:06.462678Z","iopub.status.idle":"2024-11-11T09:44:06.795943Z","shell.execute_reply.started":"2024-11-11T09:44:06.462634Z","shell.execute_reply":"2024-11-11T09:44:06.795071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import display","metadata":{"execution":{"iopub.status.busy":"2024-11-11T09:44:07.935788Z","iopub.execute_input":"2024-11-11T09:44:07.936700Z","iopub.status.idle":"2024-11-11T09:44:07.940811Z","shell.execute_reply.started":"2024-11-11T09:44:07.936652Z","shell.execute_reply":"2024-11-11T09:44:07.939739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"value_counts = train[\"ocr_text\"].value_counts()\n\n# Convert to a DataFrame\nvalue_counts_df = value_counts.reset_index()\nvalue_counts_df.columns = ['value', 'frequency']\n\n# Calculate cumulative frequency\nvalue_counts_df['cumulative_frequency'] = value_counts_df['frequency'].cumsum()\n\n# Show the result\nvalue_counts_df.head(30)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T09:44:08.521672Z","iopub.execute_input":"2024-11-11T09:44:08.522538Z","iopub.status.idle":"2024-11-11T09:44:08.555329Z","shell.execute_reply.started":"2024-11-11T09:44:08.522480Z","shell.execute_reply":"2024-11-11T09:44:08.554341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = train \nocr_text_filtered = {}\nreplacement = {}\n\n# Process each category separately\nfor cat in df.Category.unique():\n    # Filter ocr_text for the current category where it has more than 3 characters and count occurrences\n    ocr_text_counts = df[(df.Category == cat) & (df.ocr_text.str.len() >= 3)]['ocr_text'].value_counts()\n    \n    # Keep only values that appear more than 10 times in the current category\n    filtered_values = ocr_text_counts[ocr_text_counts >= 44].index.to_numpy()\n    ocr_text_filtered[cat] = filtered_values\n    \n    # Filter the DataFrame for rows that match the filtered ocr_text values for this category\n    cat_filtered_df = df[(df.Category == cat) & (df['ocr_text'].isin(filtered_values))]\n    \n    # Define a function to get the most common non-null value, or null if all values are null\n    def most_common_or_null(series):\n        non_null_series = series.dropna()\n        value_counts = non_null_series.value_counts()\n        common_values = value_counts[value_counts >= 3]\n        \n        if not common_values.empty:\n            return common_values.idxmax()  # Most common value with more than 8 occurrences\n        else:\n            return None  # Return None if no value has more than 8 occurrences\n\n    # Group by 'ocr_text' and apply the most_common_or_null function to each attribute column\n    result_df = cat_filtered_df.groupby('ocr_text').agg({f'attr_{i}': most_common_or_null for i in range(1, 11)}).reset_index()\n    \n    # Initialize a dictionary for this category in replacement\n    replacement[cat] = {}\n    \n    # Populate replacement dictionary with values from result_df for the current category\n    for ind, row in result_df.iterrows():\n        replacement[cat][row['ocr_text']] = [row[f'attr_{i}'] for i in range(1, 11)]\n\n# replacement now has the structure replacement[cat][ocr_text]\nreplacement\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T09:44:09.212051Z","iopub.execute_input":"2024-11-11T09:44:09.212437Z","iopub.status.idle":"2024-11-11T09:44:09.828511Z","shell.execute_reply.started":"2024-11-11T09:44:09.212399Z","shell.execute_reply":"2024-11-11T09:44:09.827480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels=[f\"attr_{i}\" for i in range (1,11)]","metadata":{"execution":{"iopub.status.busy":"2024-11-11T09:44:11.392540Z","iopub.execute_input":"2024-11-11T09:44:11.393453Z","iopub.status.idle":"2024-11-11T09:44:11.398036Z","shell.execute_reply.started":"2024-11-11T09:44:11.393408Z","shell.execute_reply":"2024-11-11T09:44:11.396886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt = 0\n\nfor ind, row in train.iterrows():\n    # Skip rows where 'ocr_text' is NaN or does not exist in replacement for the given category\n    if pd.isna(row.ocr_text) or row.ocr_text not in replacement[row.Category]:\n        continue\n\n    # Iterate through each label and update if needed\n    for j, i in enumerate(labels):\n        replacement_value = replacement[row.Category][row.ocr_text][j]\n        # Check if replacement value is not NaN and differs from the current value\n        if pd.notna(replacement_value) and replacement_value != train.loc[ind, i]:\n            cnt += 1\n            train.loc[ind, i] = replacement_value\ncnt\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T09:44:12.845945Z","iopub.execute_input":"2024-11-11T09:44:12.846346Z","iopub.status.idle":"2024-11-11T09:44:59.560423Z","shell.execute_reply.started":"2024-11-11T09:44:12.846308Z","shell.execute_reply":"2024-11-11T09:44:59.559381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.to_csv(\"pre_processed_train.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-11-11T09:45:02.415220Z","iopub.execute_input":"2024-11-11T09:45:02.416111Z","iopub.status.idle":"2024-11-11T09:45:02.901489Z","shell.execute_reply.started":"2024-11-11T09:45:02.416063Z","shell.execute_reply":"2024-11-11T09:45:02.900647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}